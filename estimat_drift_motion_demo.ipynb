{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, json, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spikeinterface.core as si\n",
    "import spikeinterface.extractors as se\n",
    "import probeinterface as pi\n",
    "from probeinterface.plotting import plot_probe\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.widgets as sw\n",
    "from spikeinterface.sortingcomponents.motion import (\n",
    "    correct_motion_on_peaks,\n",
    "    interpolate_motion,\n",
    "    estimate_motion,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimate_drift_motion import AP_band_drift_estimation, LFP_band_drift_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFP_band_drift_estimation(group,raw_rec,oe_folder):\n",
    "    lfprec = spre.bandpass_filter(raw_rec,freq_min=0.5,freq_max=250,margin_ms=1500.,filter_order=3,dtype=\"float32\",add_reflect_padding=True)\n",
    "    lfprec = spre.common_reference(lfprec,reference=\"global\", operator=\"median\")\n",
    "    lfprec = spre.resample(lfprec, resample_rate=250, margin_ms=1000)\n",
    "    lfprec = spre.average_across_direction(lfprec)\n",
    "    fig0=plt.figure()\n",
    "    ax=fig0.add_subplot(121)\n",
    "    sw.plot_traces(lfprec, backend=\"matplotlib\", mode=\"auto\",ax=ax,time_range=(0, 1))\n",
    "    #sw.plot_traces(lfprec, backend=\"matplotlib\", mode=\"auto\", ax=ax, clim=(-0.05, 0.05),time_range=(0, 20))\n",
    "    motion_lfp = estimate_motion(lfprec, method='dredge_lfp', rigid=True, progress_bar=True)\n",
    "    ax=fig0.add_subplot(122)\n",
    "    sw.plot_motion(motion_lfp, mode='line', ax=ax)\n",
    "    motion_folder = oe_folder / f\"lfp_motion_shank{group}\"\n",
    "    if Path(motion_folder).is_dir():\n",
    "        pass\n",
    "    else:\n",
    "        motion_folder.mkdir(parents=True, exist_ok=True)\n",
    "    fig0.savefig(motion_folder / \"dredge_lfp.png\")\n",
    "    plt.show()\n",
    "    return motion_lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thisDir = r\"Z:\\DATA\\experiment_openEphys\\H-series-128channels\\2025-03-23_21-33-38\"\n",
    "thisDir = r\"Z:\\DATA\\experiment_openEphys\\H-series-128channels\\2025-03-23_20-47-26\"\n",
    "json_file = \"./analysis_methods_dictionary.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(oe_folder,analysis_methods):\n",
    "    this_experimenter = analysis_methods.get(\"experimenter\")\n",
    "    probe_type = analysis_methods.get(\"probe_type\")\n",
    "    if (\n",
    "        analysis_methods.get(\"load_prepocessed_file\") == True\n",
    "        and (oe_folder / \"preprocessed_compressed.zarr\").is_dir()\n",
    "    ):\n",
    "        recording_saved = si.read_zarr(oe_folder / \"preprocessed_compressed.zarr\")\n",
    "        print(recording_saved.get_property_keys())\n",
    "        fs = recording_saved.get_sampling_frequency()\n",
    "        data_to_load=recording_saved \n",
    "    elif (\n",
    "        analysis_methods.get(\"load_prepocessed_file\") == True\n",
    "        and (oe_folder / \"preprocessed\").is_dir()\n",
    "    ):\n",
    "        print(\n",
    "            \"Looks like you do not have compressed files. Read the original instead\"\n",
    "        )\n",
    "        recording_saved = si.load_extractor(oe_folder / \"preprocessed\")\n",
    "        fs = recording_saved.get_sampling_frequency()\n",
    "        data_to_load=recording_saved \n",
    "    else:\n",
    "        print(\"Load meta information from openEphys\")\n",
    "\n",
    "        raw_rec = se.read_openephys(oe_folder, load_sync_timestamps=True)\n",
    "        # To show the start of recording time\n",
    "        # raw_rec.get_times()[0]\n",
    "        event = se.read_openephys_event(oe_folder)\n",
    "        # event_channel_ids=channel_ids\n",
    "        # events = event.get_events(channel_id=channel_ids[1], segment_index=0)# a complete record of events including [('time', '<f8'), ('duration', '<f8'), ('label', '<U100')]\n",
    "        events_times = event.get_event_times(\n",
    "            channel_id=event.channel_ids[1], segment_index=0\n",
    "        )  # this record ON phase of sync pulse\n",
    "        fs = raw_rec.get_sampling_frequency()\n",
    "        if analysis_methods.get(\"load_raw_traces\") == True:\n",
    "            trace_snippet = raw_rec.get_traces(\n",
    "                start_frame=int(fs * 0), end_frame=int(fs * 2)\n",
    "            )\n",
    "\n",
    "        ################load probe information################\n",
    "        if probe_type == \"P2\":\n",
    "            manufacturer = \"cambridgeneurotech\"\n",
    "            probe_name = \"ASSY-37-P-2\"\n",
    "            probe = pi.get_probe(manufacturer, probe_name)\n",
    "            print(probe)\n",
    "            probe.wiring_to_device(\"ASSY-116>RHD2132\")\n",
    "            probe.to_dataframe(complete=True).loc[\n",
    "                :, [\"contact_ids\", \"shank_ids\", \"device_channel_indices\"]\n",
    "            ]\n",
    "        elif probe_type == \"H10_stacked\":\n",
    "            stacked_probes = pi.read_probeinterface(\"H10_stacked_probes.json\")\n",
    "            probe = stacked_probes.probes[0]\n",
    "        else:\n",
    "            print(\"the name of probe not identified. stop the programme\")\n",
    "            exit()\n",
    "            \n",
    "        # drop AUX channels here\n",
    "        raw_rec = raw_rec.set_probe(probe,group_mode='by_shank')\n",
    "        probe_rec = raw_rec.get_probe()\n",
    "        probe_rec.to_dataframe(complete=True).loc[\n",
    "            :, [\"contact_ids\", \"device_channel_indices\"]\n",
    "        ]\n",
    "\n",
    "        raw_rec.annotate(\n",
    "            description=f\"Dataset of {this_experimenter}\"\n",
    "        )\n",
    "        data_to_load=raw_rec\n",
    "    \n",
    "    return data_to_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_folder = Path(thisDir)\n",
    "if isinstance(json_file, dict):\n",
    "    analysis_methods = json_file\n",
    "else:\n",
    "    with open(json_file, \"r\") as f:\n",
    "        print(f\"load analysis methods from file {json_file}\")\n",
    "        analysis_methods = json.loads(f.read())\n",
    "\n",
    "motion_corrector = analysis_methods.get(\"motion_corrector\")\n",
    "n_cpus = os.cpu_count()\n",
    "n_jobs = n_cpus - 4\n",
    "job_kwargs = dict(n_jobs=n_jobs, chunk_duration=\"1s\", progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"load_prepocessed_file\": False})\n",
    "if 'raw_rec' in locals():\n",
    "    pass\n",
    "else:\n",
    "    raw_rec=load_data(oe_folder,analysis_methods)\n",
    "raw_rec = spre.astype(raw_rec, np.float32)\n",
    "raw_rec = spre.depth_order(raw_rec)\n",
    "raw_rec_dict = raw_rec.split_by(property='group', outputs='dict')\n",
    "motion_lfp_dict={}\n",
    "for group, rec_per_shank in raw_rec_dict.items():\n",
    "    motion_lfp=LFP_band_drift_estimation(group,rec_per_shank,oe_folder)\n",
    "    motion_lfp_dict[group]=motion_lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"load_prepocessed_file\": True})\n",
    "if (analysis_methods.get(\"load_prepocessed_file\") == True) and (oe_folder / \"preprocessed_compressed.zarr\").is_dir():\n",
    "    recording_saved=load_data(oe_folder,analysis_methods)\n",
    "    fs = recording_saved.get_sampling_frequency()\n",
    "else:\n",
    "    if 'raw_rec' in locals():\n",
    "        pass\n",
    "    else:\n",
    "        raw_rec=load_data(oe_folder,analysis_methods)\n",
    "    fs = raw_rec.get_sampling_frequency()\n",
    "    recording_f = spre.bandpass_filter(raw_rec, freq_min=600, freq_max=6000)\n",
    "    if analysis_methods.get(\"analyse_good_channels_only\") == True:\n",
    "        \"\"\"\n",
    "        This step should be done before saving preprocessed files because ideally the preprocessed file we want to create is something ready for spiking\n",
    "        detection, which means neural traces gone through bandpass filter and common reference.\n",
    "        However, applying common reference takes signals from channels of interest which requires us to decide what we want to do with other bad or noisy channels first.\n",
    "        \"\"\"\n",
    "        bad_channel_ids, channel_labels = spre.detect_bad_channels(\n",
    "            recording_f, method=\"coherence+psd\"\n",
    "        )  # bad_channel_ids=np.array(['CH1','CH2','CH3','CH4','CH5','CH6','CH7','CH8','CH9','CH10','CH11','CH12','CH13','CH14','CH15','CH16'],dtype='<U64')\n",
    "        #bad channel ids in ['CH2' 'CH22' 'CH25' 'CH27' 'CH29' 'CH30' 'CH31' 'CH32' 'CH33' 'CH34''CH35' 'CH36' 'CH37' 'CH38' 'CH39' 'CH41' 'CH43' 'CH80' 'CH112'] in 2025-03-19_18-02-13\"\n",
    "        print(\"bad_channel_ids\", bad_channel_ids)\n",
    "        print(\"channel_labels\", channel_labels)\n",
    "\n",
    "        recording_f = recording_f.remove_channels(\n",
    "            bad_channel_ids\n",
    "        )  # need to check if I can do this online\n",
    "                    ##not sure if I should apply CAR by shank by shank\n",
    "    recording_cmr = spre.common_reference(\n",
    "            recording_f, reference=\"global\", operator=\"median\"\n",
    "        )\n",
    "if \"recording_cmr\" in locals():\n",
    "    rec_of_interest = recording_cmr\n",
    "else:\n",
    "    rec_of_interest = recording_saved\n",
    "    rec_of_interest.annotate(\n",
    "        is_filtered=True\n",
    "    )  # needed to add this somehow because when loading a preprocessed data saved in the past, that data would not be labeled as filtered data\n",
    "# Slice the recording if needed\n",
    "if analysis_methods.get(\"analyse_entire_recording\") == False:\n",
    "    start_sec = 1\n",
    "    end_sec = 899\n",
    "    rec_of_interest = rec_of_interest.frame_slice(\n",
    "        start_frame=start_sec * fs, end_frame=end_sec * fs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_dict = rec_of_interest.split_by(property='group', outputs='dict')\n",
    "win_um=100    \n",
    "recording_corrected_dict = {}\n",
    "motion_ap_dict={}\n",
    "for group, sub_recording in recordings_dict.items():\n",
    "    recording_corrected,motion_ap_list=AP_band_drift_estimation(group,sub_recording,oe_folder,analysis_methods,win_um,job_kwargs)\n",
    "    recording_corrected_dict[group]=recording_corrected\n",
    "    motion_ap_dict[group]=motion_ap_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike_interface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
